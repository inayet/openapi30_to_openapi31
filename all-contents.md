# Project Documentation


## Table of Contents

- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [openapi_converter.py](#openapi_converter-py)
- [CODE_OF_CONDUCT.md](#CODE_OF_CONDUCT-md)
- [all-contents.md](#all-contents-md)
- [md_content_aggregator.py](#md_content_aggregator-py)
- [SECURITY.md](#SECURITY-md)
- [__init__.py](#__init__-py)
- [content.md](#content-md)
- [README.md](#README-md)
- [useful.git-create-new-repo.py](#useful-git-create-new-repo-py)
- [openapi_converter_main.py](#openapi_converter_main-py)
- [useful.git-update-all-branches.py](#useful-git-update-all-branches-py)
## Directory Structure
```json
[
  {"type":"directory","name":".","contents":[
    {"type":"directory","name":"assets","contents":[
      {"type":"file","name":"openapi310.png"}
    ]},
    {"type":"directory","name":"configuration","contents":[
      {"type":"file","name":"display_project_files.ignore.bk"},
      {"type":"file","name":"display_project_files.include.bk"}
    ]},
    {"type":"directory","name":"data","contents":[
      {"type":"file","name":"calendars.json"},
      {"type":"file","name":"calendars.yml"}
    ]},
    {"type":"directory","name":"docs","contents":[
      {"type":"file","name":"CODE_OF_CONDUCT.md"},
      {"type":"file","name":"docs-content.md"},
      {"type":"file","name":"SECURITY.md"}
    ]},
    {"type":"directory","name":"git-utils","contents":[
      {"type":"file","name":"git-utils-content.md"},
      {"type":"file","name":"useful.git-create-new-repo.py"},
      {"type":"file","name":"useful.git-update-all-branches.py"}
    ]},
    {"type":"directory","name":"src","contents":[
      {"type":"directory","name":"__pycache__","contents":[
        {"type":"file","name":"content.md"},
        {"type":"file","name":"openapi_converter.cpython-311.pyc"},
        {"type":"file","name":"src-__pycache__-content.md"}
      ]},
      {"type":"file","name":"__init__.py"},
      {"type":"file","name":"md_content_aggregator.py"},
      {"type":"file","name":"openapi_converter_main.py"},
      {"type":"file","name":"openapi_converter.py"},
      {"type":"file","name":"src-content.md"}
    ]},
    {"type":"directory","name":"utilities","contents":[
      {"type":"file","name":"organize.py"}
    ]},
    {"type":"file","name":"all-contents.md"},
    {"type":"file","name":"License"},
    {"type":"file","name":"README.md"},
    {"type":"file","name":"repodir.txt"},
    {"type":"file","name":"requirements.txt"},
    {"type":"file","name":"script.log"}
  ]}
,
  {"type":"report","directories":9,"files":26}
]

```


### all-contents.md
# Project Documentation


## Table of Contents

- [openapi_converter_main.py](#openapi_converter_main-py)
- [README.md](#README-md)
- [useful.git-create-new-repo.py](#useful-git-create-new-repo-py)
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)
- [md_content_aggregator.py](#md_content_aggregator-py)
- [useful.git-update-all-branches.py](#useful-git-update-all-branches-py)
- [all-contents.md](#all-contents-md)
- [openapi_converter.py](#openapi_converter-py)
- [CODE_OF_CONDUCT.md](#CODE_OF_CONDUCT-md)
- [SECURITY.md](#SECURITY-md)
- [__init__.py](#__init__-py)
## Directory Structure
```json
[
  {"type":"directory","name":".","contents":[
    {"type":"directory","name":"assets","contents":[
      {"type":"file","name":"openapi310.png"}
    ]},
    {"type":"directory","name":"configuration","contents":[
      {"type":"file","name":"display_project_files.ignore.bk"},
      {"type":"file","name":"display_project_files.include.bk"}
    ]},
    {"type":"directory","name":"data","contents":[
      {"type":"file","name":"calendars.json"},
      {"type":"file","name":"calendars.yml"}
    ]},
    {"type":"directory","name":"docs","contents":[
      {"type":"file","name":"CODE_OF_CONDUCT.md"},
      {"type":"file","name":"docs-content.md"},
      {"type":"file","name":"SECURITY.md"}
    ]},
    {"type":"directory","name":"git-utils","contents":[
      {"type":"file","name":"git-utils-content.md"},
      {"type":"file","name":"useful.git-create-new-repo.py"},
      {"type":"file","name":"useful.git-update-all-branches.py"}
    ]},
    {"type":"directory","name":"src","contents":[
      {"type":"directory","name":"__pycache__","contents":[
        {"type":"file","name":"content.md"},
        {"type":"file","name":"openapi_converter.cpython-311.pyc"},
        {"type":"file","name":"src-__pycache__-content.md"}
      ]},
      {"type":"file","name":"__init__.py"},
      {"type":"file","name":"md_content_aggregator.py"},
      {"type":"file","name":"openapi_converter_main.py"},
      {"type":"file","name":"openapi_converter.py"},
      {"type":"file","name":"src-content.md"}
    ]},
    {"type":"directory","name":"utilities","contents":[
      {"type":"file","name":"organize.py"}
    ]},
    {"type":"file","name":"all-contents.md"},
    {"type":"file","name":"License"},
    {"type":"file","name":"README.md"},
    {"type":"file","name":"repodir.txt"},
    {"type":"file","name":"requirements.txt"},
    {"type":"file","name":"script.log"}
  ]}
,
  {"type":"report","directories":9,"files":26}
]

```


### all-contents.md
# Project Documentation


## Table of Contents

- [useful.git-update-all-branches.py](#useful-git-update-all-branches-py)
- [openapi_converter_main.py](#openapi_converter_main-py)
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [useful.git-create-new-repo.py](#useful-git-create-new-repo-py)
- [content.md](#content-md)
- [openapi_converter.py](#openapi_converter-py)
- [md_content_aggregator.py](#md_content_aggregator-py)
- [README.md](#README-md)
- [SECURITY.md](#SECURITY-md)
- [__init__.py](#__init__-py)
- [CODE_OF_CONDUCT.md](#CODE_OF_CONDUCT-md)
## Directory Structure
```json
[
  {"type":"directory","name":".","contents":[
    {"type":"directory","name":"assets","contents":[
      {"type":"file","name":"openapi310.png"}
    ]},
    {"type":"directory","name":"configuration","contents":[
      {"type":"file","name":"display_project_files.ignore.bk"},
      {"type":"file","name":"display_project_files.include.bk"}
    ]},
    {"type":"directory","name":"data","contents":[
      {"type":"file","name":"calendars.json"},
      {"type":"file","name":"calendars.yml"}
    ]},
    {"type":"directory","name":"docs","contents":[
      {"type":"file","name":"CODE_OF_CONDUCT.md"},
      {"type":"file","name":"docs-content.md"},
      {"type":"file","name":"SECURITY.md"}
    ]},
    {"type":"directory","name":"git-utils","contents":[
      {"type":"file","name":"git-utils-content.md"},
      {"type":"file","name":"useful.git-create-new-repo.py"},
      {"type":"file","name":"useful.git-update-all-branches.py"}
    ]},
    {"type":"directory","name":"src","contents":[
      {"type":"directory","name":"__pycache__","contents":[
        {"type":"file","name":"content.md"},
        {"type":"file","name":"openapi_converter.cpython-311.pyc"},
        {"type":"file","name":"src-__pycache__-content.md"}
      ]},
      {"type":"file","name":"__init__.py"},
      {"type":"file","name":"md_content_aggregator.py"},
      {"type":"file","name":"openapi_converter_main.py"},
      {"type":"file","name":"openapi_converter.py"},
      {"type":"file","name":"src-content.md"}
    ]},
    {"type":"directory","name":"utilities","contents":[
      {"type":"file","name":"organize.py"}
    ]},
    {"type":"file","name":"License"},
    {"type":"file","name":"README.md"},
    {"type":"file","name":"repodir.txt"},
    {"type":"file","name":"requirements.txt"},
    {"type":"file","name":"script.log"}
  ]}
,
  {"type":"report","directories":9,"files":25}
]

```


### README.md
# Convert OpenAPI 3.0.0 to OpenAPI 3.1.0 Converter

> ![OpenAPI](assets/openapi310.png)

## Table of Contents

- [Description](#description)
- [How to Use](#how-to-use)
- [Scripts](#scripts)
- [Configuration Files](#configuration-files)
- [Documentation](#documentation)
- [Dependencies](#dependencies)
- [Contributing](#contributing)
- [License](#license)

## Description

Welcome to the **OpenAPI 3.0.0 to OpenAPI 3.1.0 Converter** repository. This collection of tools and scripts is designed to seamlessly convert OpenAPI 3.0.0 specifications to the upgraded OpenAPI 3.1.0 format.

## How to Use

To efficiently convert your OpenAPI 3.0.0 specifications to OpenAPI 3.1.0 format, follow these steps:

### 1. `openapi_converter_main.py`

This script is the heart of the conversion process. It takes an OpenAPI 3.0.0 specification in JSON format and generates a 3.1.0 YAML specification.

Usage:

```bash
python openapi_converter_main.py [input_file.json] [output_file.yml]
```

### 2. `useful.git-create-new-repo.py`

![GitHub](https://www.vectorlogo.zone/logos/github/github-ar21.svg)

Need a new GitHub repository? This script not only initializes a repository but also sets up main, production, and development branches for your project.

Usage:

```bash
python useful.git-create-new-repo.py
```

### 3. `useful.git-update-development-production.py`

Run this then when ready to update main branch run [useful.git-update-production-main.py](useful.git-update-production-main.py) Update your development and production branches efficiently.

Usage:

```bash
python useful.git-update-development-production.py
```


### 4. `useful.git-update-production-main.py`

Keep your production and main branches up to date with this script.

Usage:

```bash
python useful.git-update-production-main.py
```

### 5. `md_content_aggregator.py`

Asynchronously scan your directory to generate a content markdown file based on the files present.

Usage:

```bash
python md_content_aggregator.py
```

## Configuration Files

### `display_project_files.ignore`

This file contains patterns of files and directories to ignore when generating documentation using the `md_content_aggregator.py` script.

### `.gitignore`

This file specifies patterns of files and directories to be ignored by Git. It helps maintain a clean repository by excluding unnecessary files and build artifacts.

### `requirements.txt`

This file lists the necessary Python packages required to run the scripts in this repository.

## Documentation

### `CODE_OF_CONDUCT.md`

This document outlines the code of conduct for contributors and users of the repository, ensuring a respectful and inclusive environment for collaboration.

### `SECURITY.md`

This document details the security policy for the repository. Learn how to report vulnerabilities and understand our commitment to promptly addressing security concerns.

## Dependencies

Install the required dependencies from `requirements.txt`:

```bash
pip install -r requirements.txt
```

## Contributing

Contributions are welcome! Please read our [Contributing Guidelines](CONTRIBUTING.md) for details on how to contribute to this project.

## License

This project is licensed under the MIT License. View the [License](LICENSE) file in the repository for more details.

## Future Plans

As we continually strive to enhance and streamline the OpenAPI conversion process, we have some exciting developments on the horizon:

### 1. Automating OpenAPI Spec Retrieval

Our upcoming feature aims to simplify the acquisition of OpenAPI specifications. We're working on an automated mechanism to fetch specs directly from websites and API endpoints. This eliminates manual downloading, providing real-time access to the most current information.

### 2. Automated Conversion and External Validation

Our focus extends beyond conversion alone. We're in the process of creating an automated pipeline that not only converts OpenAPI 3.0.0 specs to 3.1.0 but also employs external tools to validate the converted files.

### 3. Enhancing Quality with OpenAPI API Validator

In our pursuit of accurate and compliant OpenAPI specifications, we're thrilled to integrate the OpenAPI API Validator into our conversion process. This powerful validator ensures the quality, accuracy, and compliance of your converted OpenAPI specs.

By incorporating the OpenAPI API Validator, we're taking proactive steps to eliminate errors and inconsistencies from your converted specifications. This tool empowers a seamless transition from OpenAPI 3.0.0 to 3.1.0 while maintaining the highest accuracy standards.

### Join Us 
We invite you to join us on this journey towards excellence. Your feedback, ideas, and suggestions are invaluable as we enhance your OpenAPI conversion experience. Share your thoughts in the Issues section, and stay tuned for updates as we roll out these exciting features to elevate your OpenAPI conversion workflows!

## Directory Structure
```json
[
  {"type":"directory","name":"./git-utils","contents":[
    {"type":"file","name":"useful.git-create-new-repo.py"},
    {"type":"file","name":"useful.git-update-all-branches.py"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### useful.git-update-all-branches.py
```python
"""
Git Branch Update Utility

Methods:
- log_to_db: Log actions to SQLite database
- backup_database: Back up SQLite database  
- stash_changes: Stash local changes
- pop_changes: Pop stashed changes
- check_for_merge_conflicts: Check and handle merge conflicts
- handle_pull_failure: Handle pull failures
- merge_and_push: Merge source into target branch and push
- fetch_all_remote_branches: Fetch all remote branches
- ensure_correct_branch_for_action: Ensure user is on correct branch
- update_branches: Update target branches with source changes
- update_branch_with_source: Update target branch with source changes 
- get_all_branches: Get all branches in the repo
- get_all_local_branches: Get all local branches in the repo
- select_source_branch: Select source branch interactively
- select_target_branches: Select target branches interactively
- main: Main function

This script provides functionalities to:
1. Dynamically list all branches in the repository.
2. Allow users to select a source branch and multiple target branches.
3. Update the target branches with the latest changes from the source branch.  
4. Ensure users are on the correct branch before proceeding with updates.
5. Handle merge conflicts and allow users to decide how to proceed.
6. Log all actions to an SQLite database. 
7. Backup the SQLite database.
8. Fetch all remote branches to ensure the local repository is up-to-date.
"""

import os
import logging
import subprocess
import sqlite3
import shutil

DATABASE_NAME = "git_actions_log.db"

\# Set up logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()])

def log_to_db(action, message):
    with sqlite3.connect(DATABASE_NAME) as conn:
        cursor = conn.cursor()
        cursor.execute('''CREATE TABLE IF NOT EXISTS actions
                          (timestamp TEXT, action TEXT, message TEXT)''')
        cursor.execute("INSERT INTO actions (timestamp, action, message) VALUES (datetime('now'), ?, ?)",
                       (action, message))
        conn.commit()

def backup_database():
    backup_name = DATABASE_NAME.split('.')[0] + "_backup.db"
    shutil.copy(DATABASE_NAME, backup_name)
    logging.info(f"Backed up database to {backup_name}.")
    log_to_db("INFO", f"Backed up database to {backup_name}.")

def stash_changes():
    subprocess.run(["git", "stash", "push", "-m", "changes_stash_for_script"])

def pop_changes():
    stashes = subprocess.getoutput("git stash list")
    if "changes_stash_for_script" in stashes:
        subprocess.run(["git", "stash", "pop"])

def check_for_merge_conflicts():
    status = subprocess.getoutput("git status")
    if "You have unmerged paths" in status or "fix conflicts" in status:
        logging.error("You have unresolved merge conflicts.")
        print("1: Resolve conflicts manually and exit script.")
        print("2: Prioritize local changes.")
        print("3: Prioritize remote changes.")
        choice = input("Enter choice (1/2/3): ")

        if choice == '1':
            print("Resolve the conflicts manually and then run the script again.")
            exit(1)
        elif choice == '2':
            subprocess.run(["git", "checkout", "--", "."])
        elif choice == '3':
            current_branch = subprocess.getoutput("git branch --show-current")
            subprocess.run(["git", "reset", "--hard", f"origin/{current_branch}"])
        else:
            logging.warning("Invalid choice. Exiting.")
            exit(1)

def handle_pull_failure(branch_name):
    logging.error(f"Failed to pull from {branch_name}")
    user_decision = input(f"Failed to pull from {branch_name}. Do you want to proceed? (yes/no): ")
    if user_decision.lower() != 'yes':
        return False

    priority_decision = input("Which files do you want to prioritize? (local/remote): ")
    if priority_decision.lower() == 'local':
        subprocess.run(["git", "checkout", "--", "."])
    elif priority_decision.lower() == 'remote':
        subprocess.run(["git", "reset", "--hard", f"origin/{branch_name}"])
    return True

def merge_and_push(source_branch, target_branch):
    merge_result = subprocess.run(["git", "merge", source_branch, "--no-ff",
                                  "-m", f"Merging changes from {source_branch} into {target_branch}"], capture_output=True, text=True)
    if merge_result.returncode != 0:
        error_msg = f"Failed to merge {source_branch} into {target_branch}. Resolve conflicts manually."
        logging.error(error_msg + "\n" + merge_result.stderr)
        return

    push_result = subprocess.run(["git", "push", "origin", target_branch], capture_output=True, text=True)
    if push_result.returncode != 0:
        error_msg = f"Failed to push changes to {target_branch}."
        logging.error(error_msg + "\n" + push_result.stderr)
        return

    success_msg = f"Merged '{source_branch}' into '{target_branch}' and pushed changes."
    logging.info(success_msg)

def fetch_all_remote_branches():
    result = subprocess.run(["git", "fetch", "--all"], capture_output=True, text=True)
    if result.returncode != 0:
        logging.error("Failed to fetch remote branches. Please check your internet connection.")
        exit(1)
    else:
        logging.info("Successfully fetched all remote branches.")

def ensure_correct_branch_for_action(source_branch):
    current_branch = subprocess.getoutput("git branch --show-current")
    if current_branch.replace('*', '').strip() != source_branch.replace('*', '').strip():
        switch = input(f"You must be on the '{source_branch}' branch to update other branches. Switch to '{source_branch}'? (yes/no): ")
        if switch.lower() == 'yes':
            subprocess.run(["git", "checkout", source_branch])
            check_for_merge_conflicts()
        else:
            logging.warning("Operation cancelled by user.")
            exit(1)


def update_branches(source_branch, target_branches):
    """Update target branches with source changes."""
    print(f"Will merge changes from '{source_branch}' into the following branches: {', '.join(target_branches)}")
    confirmation = input("Do you want to proceed? (yes/no): ")
    if confirmation.lower() != 'yes':
        logging.info("Operation cancelled by user.")
        return

    check_for_merge_conflicts()
    stash_changes()

    for target_branch in target_branches:
        if target_branch == source_branch:
            logging.info(f"Skipping {source_branch} as it's the same as the source branch.")
            continue

        subprocess.run(["git", "checkout", target_branch])
        if not update_branch_with_source(target_branch, source_branch):
            logging.error(f"Failed to update {target_branch} with changes from {source_branch}")
            continue

    subprocess.run(["git", "checkout", source_branch])
    pop_changes()

def update_branch_with_source(target_branch, source_branch):
    pull_result = subprocess.run(["git", "pull", "origin", source_branch], capture_output=True, text=True)
    if pull_result.returncode != 0:
        logging.error(f"Failed to pull latest code from {source_branch}.")
        return False

    subprocess.run(["git", "checkout", target_branch])
    pull_target_result = subprocess.run(["git", "pull", "origin", target_branch], capture_output=True, text=True)
    if pull_target_result.returncode != 0 and not handle_pull_failure(target_branch):
        return False

    merge_and_push(source_branch, target_branch)
    return True

def get_all_branches():
    branches = subprocess.getoutput("git branch -a")
    return [branch.strip() for branch in branches.split('\n')]

def get_all_local_branches():
    branches = subprocess.getoutput("git branch")
    return [branch.strip() for branch in branches.split('\n')]

def clean_branch_name(branch):
    """Standardize and clean the branch name."""
    return branch.replace('*', '').strip().split('/')[-1]

def select_source_branch():
    """Select source branch interactively."""
    print("Select the source branch:")
    all_branches = get_all_branches()
    for idx, branch in enumerate(all_branches, start=1):
        print(f"{idx}: {branch}")

    choice = int(input(f"Enter choice (1 to {len(all_branches)}): "))
    if choice < 1 or choice > len(all_branches):
        logging.error("Invalid choice.")
        exit(2)

    source_branch = clean_branch_name(all_branches[choice - 1])
    return source_branch

def select_target_branches():
    """Select target branches interactively."""
    print("Select the target branches:")
    
    all_local_branches = get_all_local_branches()
    for idx, branch in enumerate(all_local_branches, start=1):
        print(f"{idx}: {branch}")

    choices = list(map(int, input("Enter choices (comma separated): ").split(',')))
    target_branches = [all_local_branches[choice - 1].replace('*', '').strip() for choice in choices]
    return target_branches



def handle_unstaged_changes():
    """Handle any unstaged changes in the repo."""
    status = subprocess.getoutput("git status")
    if "Changes not staged for commit:" in status:
        print("\nThere are some unstaged changes in your repository. Here's what changed:\n")
        os.system("git diff")
        
        \# Extract filenames here, outside of the choice blocks.
        filenames = [line.split(":")[1].strip() for line in status.split("\n") if "modified:" in line]

        print("\nOptions:")
        print("1: Stage and commit the changes.")
        print("2: Discard the changes.")
        print("3: Exit and handle the changes manually.")
        
        choice = input("\nEnter your choice (1/2/3): ")
        
        if choice == '1':
            for filename in filenames:
                subprocess.run(["git", "add", filename])
            commit_message = input("Enter commit message: ")
            subprocess.run(["git", "commit", "-m", commit_message])
            print("Changes have been staged and committed.")
        
        elif choice == '2':
            for filename in filenames:
                subprocess.run(["git", "checkout", "--", filename])
            print("Changes have been discarded.")
        
        elif choice == '3':
            print("Exiting. You can handle the changes manually.")
            exit(1)



def main():
    logging.info("Git Branch Update Utility")
    
    fetch_all_remote_branches()
    backup_database()
    
    source_branch = select_source_branch()
    ensure_correct_branch_for_action(source_branch)
    
    target_branches = select_target_branches()
    confirm = input(f"Will merge changes from '{source_branch}' into the following branches: {', '.join(target_branches)}\nDo you want to proceed? (yes/no): ")
    
    if confirm.lower() != 'yes':
        logging.warning("Operation cancelled by user.")
        exit(1)
    
    update_branches(source_branch, target_branches)
    handle_unstaged_changes()

if __name__ == "__main__":
    main()
```


### useful.git-create-new-repo.py
```python
\# Filename: useful.git\-create\-new\-repo.py
\# This script helps create a new Git repository

import os
import logging
import subprocess

\# Set up logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()])

def initialize_and_setup_repo():
    \# Set the absolute path for the current directory
    directory_path = os.path.abspath('.')
    logging.info(f"Directory path: {directory_path}")
    
    \# Get the last part of the directory path
    repo_name = os.path.basename(directory_path)
    logging.info(f"Repo name: {repo_name}")

    \# Check if the directory already has a Git repo
    if os.path.isdir(os.path.join(directory_path, ".git")):
        logging.info("Directory already has a git repo")
        return

    \# Create a new GitHub repository with the current directory name
    subprocess.run(["gh", "repo", "create", repo_name, "--private", "-y"])
    logging.info(f"GitHub repository '{repo_name}' created successfully!")

    \# Initialize a new Git repo
    subprocess.run(["git", "init", "--quiet"])

    \# Add all of the files to the repo
    subprocess.run(["git", "add", "*"])

    \# Commit the changes to the repo
    subprocess.run(["git", "commit", "-m", "Initial commit on main branch"])

    \# Add the remote origin
    remote_url = f"https://github.com/inayet/{repo_name}.git"
    subprocess.run(["git", "remote", "add", "origin", remote_url])

    \# Push the main branch to the new GitHub repository
    subprocess.run(["git", "push", "-u", "origin", "main"])

    \# Create the 'production' branch, commit, and push
    subprocess.run(["git", "checkout", "-b", "production"])
    subprocess.run(["git", "push", "-u", "origin", "production"])
    logging.info("Created and pushed 'production' branch.")

    \# Switch back to main to create the 'development' branch, commit, and push
    subprocess.run(["git", "checkout", "main"])
    subprocess.run(["git", "checkout", "-b", "development"])
    subprocess.run(["git", "push", "-u", "origin", "development"])
    logging.info("Created and pushed 'development' branch.")

    \# Log the success message
    logging.info("Repo setup complete!")

if __name__ == "__main__":
    initialize_and_setup_repo()

```

## Directory Structure
```json
[
  {"type":"directory","name":"./src","contents":[
    {"type":"directory","name":"__pycache__","contents":[
      {"type":"file","name":"content.md"},
      {"type":"file","name":"openapi_converter.cpython-311.pyc"},
      {"type":"file","name":"src-__pycache__-content.md"}
    ]},
    {"type":"file","name":"__init__.py"},
    {"type":"file","name":"md_content_aggregator.py"},
    {"type":"file","name":"openapi_converter_main.py"},
    {"type":"file","name":"openapi_converter.py"}
  ]}
,
  {"type":"report","directories":2,"files":7}
]

```


### __init__.py
```python

```


### openapi_converter_main.py
```python
\# Filename is openapi\_converter\_main.py
\# This file contains the main function to convert an OpenAPI 3.0 spec to 3.1

import argparse
import openapi_converter as converter 
import yaml
import os

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('input_file')
    parser.add_argument('output_file', nargs='?', default=None)
    args = parser.parse_args()

    if args.output_file is None:
        base_name = os.path.splitext(args.input_file)[0]  # Get the name without extension
        args.output_file = os.path.join(os.getcwd(), f"{base_name}.yml")

    if not os.path.exists(args.input_file):
        raise FileNotFoundError(f"Input file '{args.input_file}' does not exist.")

    with open(args.input_file, 'r') as f:
        openapi_dict = yaml.safe_load(f.read())  # <-- Fixed here

    try:
        converted_spec = converter.convert_openapi(openapi_dict)
        with open(args.output_file, 'w') as f:
            f.write(converted_spec)
        print(f"Converted spec saved to {args.output_file}")
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == '__main__':
    main()

```


### openapi_converter.py
```python
\# Filename openapi\_converter.py
\# This module contains functions to convert an OpenAPI 3.0 spec to 3.1

import yaml
import logging
from collections import OrderedDict

logging.basicConfig(level=logging.INFO)

def convert_openapi(openapi_dict):
    \# Input validation

    validate_required_fields(openapi_dict)
    validate_openapi_version(openapi_dict, versions=["3.0.0", "3.1.0"])
    check_incompatible_inputs(openapi_dict, incompatible_keys=["securityDefinitions"])

    \# Retain operation details

    for path in openapi_dict['paths'].values():
        for operation in path.values():
            if 'description' in operation:
                operation['x-original-description'] = operation['description']
            if 'operationId' in operation:
                operation['x-original-operationId'] = operation['operationId']

    \# Retain schema details

    for schema in openapi_dict['components']['schemas'].values():
        if 'description' in schema:
            schema['x-original-description'] = schema['description']

    \# Update to OpenAPI version 3.1.0

    openapi_dict['openapi'] = "3.1.0"

    \# Security schemes

    security_schemes = {}

    if 'securityDefinitions' in openapi_dict:
        logging.warning(
            f"'securityDefinitions' found - converting to 'securitySchemes'. "
            "This key is deprecated in OpenAPI 3.1.0 and should be replaced with 'securitySchemes'."
        )
        security_definitions = openapi_dict.pop('securityDefinitions')
        for def_name, definition in security_definitions.items():
            scheme = {
                'type': definition.get('type', 'http'),
                'scheme': definition.get('scheme', 'bearer')
            }
            if 'bearerFormat' in definition:
                scheme['bearerFormat'] = definition['bearerFormat']
            if 'description' in definition:
                scheme['description'] = definition['description']
            security_schemes[def_name] = scheme

    openapi_dict['components']['securitySchemes'] = security_schemes

    \# YAML conversion

    yaml_string = yaml.dump(openapi_dict, sort_keys=True)

    return yaml_string

\# Input validation functions

def validate_required_fields(openapi_dict):
    required_fields = ['openapi', 'info', 'paths']
    for field in required_fields:
        if field not in openapi_dict:
            raise Exception(f"Field '{field}' is required")

def validate_openapi_version(openapi_dict, versions=["3.0.0", "3.1.0"]):
    if openapi_dict['openapi'] not in versions:
        raise Exception(
            f"Input version must be one of {versions}. Found {openapi_dict['openapi']}"
        )

def check_incompatible_inputs(openapi_dict, incompatible_keys=['securityDefinitions']):
    for key in incompatible_keys:
        if key in openapi_dict:
            raise Exception(f"Input contains deprecated key '{key}'.")

```


### md_content_aggregator.py
```python
'''
Name: md_content_aggregator.py

Purpose:
The MD Content Aggregator is designed to scan a directory structure, extracting content from files that match specific criteria, and generate a content.md file for each directory and an all-contents.md file in the root directory. The generated files contain aggregated content from the scanned files, appropriately formatted in Markdown.

Methods and Functionalities:
- escape_markdown_characters_in_python_code(code: str) -> str:
    Escapes markdown special characters in a given string containing Python code to ensure they're not interpreted as markdown formatting.

- get_repo_structure(directory: str) -> str:
    Uses the tree command to generate a JSON representation of the directory structure.

- should_include(file_path: str, is_dir: bool = False) -> bool:
    Determines if a file or directory should be included based on specified patterns and extensions.

- directory_structure(directory: str) -> str:
    Retrieve the structure of a specific directory in JSON format.

- generate_filename(directory: str) -> str:
    Generates the filename for the content.md file based on the directory structure.

- generate_md_files(directory: str) -> None:
    Asynchronously processes a directory to identify files for aggregation and generate a content.md file.

- combine_md_files() -> None:
    Generates the all-contents.md file in the root directory by combining all the content.md files.

- process_directory(directory: str) -> None:
    Recursively processes directories to generate content.md files.

- main() -> None:
    The main asynchronous function that initiates the content aggregation process.

Configuration and Constants:
- EXCLUDED_EXTENSIONS: File extensions that are to be ignored.
- EXCLUSIVE_EXTENSION: Patterns and directories that the content aggregation process should exclusively focus on.
- Logging: Captures information, warnings, and error messages to script.log.

How to Use:
1. Ensure the script has access to the directories you wish to scan.
2. Run the script.
3. Once complete, find a content.md file in each directory and an all-contents.md file in the root directory.

Note: The script uses asynchronous file operations for improved performance with a large number of files or large-sized files. Ensure required libraries are installed.
'''

import os
import asyncio
import aiofiles
import logging
import fnmatch
import subprocess
import re


logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()])

EXCLUDED_EXTENSIONS = ['.db', '.log', '.sh', '.pyc', 'content.md']
EXCLUSIVE_EXTENSION = ['*.py', '*.md', 'docs/*', 'git-utils/*', 'src/*', '.']

added_content = set()


def escape_markdown_characters_in_python_code(code: str) -> str:
    """Escape markdown special characters within Python code."""
    lines = code.split('\n')
    escaped_lines = []
    for line in lines:
        if line.strip().startswith("#"):
            line = line.replace("#", r"\#")
            line = line.replace("*", r"\*")
            line = line.replace("_", r"\_")
            line = line.replace("[", r"\[")
            line = line.replace("]", r"\]")
            line = line.replace("(", r"\(")
            line = line.replace(")", r"\)")
            line = line.replace(">", r"\>")
            line = line.replace("-", r"\-")
        escaped_lines.append(line)
    return '\n'.join(escaped_lines)

def get_repo_structure(directory):
    """Retrieve the repository structure in JSON format."""
    try:
        result = subprocess.run(['tree', '--dirsfirst', '-J', directory],
                                capture_output=True, text=True, check=True)
        return result.stdout
    except subprocess.CalledProcessError as e:
        logging.error(f"Error getting repo structure: {e}")
        return ""

def should_include(file_path, is_dir=False):
    """
    Determine if a file or directory should be included based on exclusive and excluded patterns.
    """
    if is_dir:
        \# Explicitly check for directories using string methods
        dir_checks = ['docs', 'git-utils', 'src']
        return any(check in file_path for check in dir_checks)

    if any(fnmatch.fnmatch(file_path, pattern) for pattern in EXCLUDED_EXTENSIONS):
        return False

    return any(fnmatch.fnmatch(file_path, pattern) for pattern in EXCLUSIVE_EXTENSION)



def directory_structure(directory):
    """Retrieve the structure of a specific directory in JSON format."""
    try:
        result = subprocess.run(['tree', '--dirsfirst', '-J', directory],
                                capture_output=True, text=True, check=True)
        return result.stdout
    except subprocess.CalledProcessError as e:
        logging.error(f"Error getting directory structure: {e}")
        return ""



def generate_filename(directory):
    """Generate filename based on the directory structure."""
    if directory == ".":
        return "root-content.md"
    else:
        parts = [part for part in directory.split(os.sep) if part != "."]
        return "-".join(parts) + "-content.md"

async def generate_md_files(directory):
    """Generate content.md files for the specified directory."""
    logging.info(f"Processing directory: {directory}")
    content_filepath = os.path.join(directory, generate_filename(directory))
    \# Delete the existing content.md file if it exists
    if os.path.exists(content_filepath):
        os.remove(content_filepath)
    toc_content = "## Table of Contents\n"
    dir_structure = f"\n\n## Directory Structure\n```json\n{directory_structure(directory)}\n```\n\n"
    file_content_list = []

    for entry in os.scandir(directory):
        if entry.is_file() and should_include(entry.path) and entry.name != content_filepath:
            try:
                async with aiofiles.open(entry.path, 'r', encoding='utf-8') as f:
                    file_content = await f.read()

                if file_content in added_content:
                    continue
                added_content.add(file_content)

                toc_content += f"- [{entry.name}](#{entry.name.replace('.', '-')})\n"

                if entry.name.endswith('.py'):
                    file_content = escape_markdown_characters_in_python_code(file_content)
                    file_content_list.append(f"\n### {entry.name}\n```python\n{file_content}\n```\n")
                elif entry.name.endswith('.md'):
                    file_content_list.append(f"\n### {entry.name}\n{file_content}\n")
            except UnicodeDecodeError:
                logging.warning(f"Unable to read file {entry.name} as it's not in UTF-8 encoding. Skipping.")

    async with aiofiles.open(content_filepath, 'w') as f:
        await f.write(toc_content + dir_structure + '\n'.join(file_content_list))


def combine_md_files():
    combined_content_sections = ["# Project Documentation\n\n", "## Table of Contents\n"]
    \# Delete the existing all\-contents.md file if it exists
    if os.path.exists("all-contents.md"):
        os.remove("all-contents.md")
    toc_links = set()

    for directory, _, filenames in os.walk("."):
        content_md_name = generate_filename(directory)
        content_md_path = os.path.join(directory, content_md_name)
        if content_md_name in filenames:
            logging.info(f"Reading {content_md_path}")
            with open(content_md_path, 'r', encoding='utf-8') as f:
                content = f.read()

            sections = content.split("\n## ")
            toc_section = sections[0]
            toc_links.update(re.findall(r"- \[.*?\]\(.*?\)", toc_section))
            for section in sections[1:]:
                combined_content_sections.append("## " + section)

    combined_content_sections.insert(2, "\n".join(toc_links))
    combined_content_sections.append("\n\n## Repo Structure\n```json\n")
    combined_content_sections.append(get_repo_structure("."))
    combined_content_sections.append("\n```\n\n")

    with open("all-contents.md", 'w', encoding='utf-8') as f:
        f.write('\n'.join(combined_content_sections))



async def process_directory(directory):
    """Process a directory and its subdirectories to generate content.md files."""
    logging.info(f"Checking directory: {directory}")
    await generate_md_files(directory)

    for entry in os.scandir(directory):
        if entry.is_dir() and should_include(entry.path, is_dir=True):
            await process_directory(entry.path)

async def main():
    """Main asynchronous function to start content aggregation."""
    global added_content
    added_content = set()  # Reset the set
    await process_directory(".")
    combine_md_files()

if __name__ == "__main__":
    asyncio.run(main())
```

## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```



## Directory Structure
```json
[
  {"type":"directory","name":"./docs","contents":[
    {"type":"file","name":"CODE_OF_CONDUCT.md"},
    {"type":"file","name":"SECURITY.md"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### CODE_OF_CONDUCT.md
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
inayet@dreamsapi.com.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.


### SECURITY.md
### SECURITY.md

```markdown
# Security Policy

![Security](https://www.vectorlogo.zone/logos/snykio/snykio-ar21.svg)

## Supported Versions

Currently, we support the following versions of "Convert OpenAPI 3.0.0 specs to OpenAPI 3.1.0" with security updates:

| Version | Supported          |
| ------- | ------------------ |
| 1.2.x   | :white_check_mark: |
| 1.1.x   | :white_check_mark: |
| 1.0.x   | :x:                |

## Reporting a Vulnerability

If you discover any vulnerabilities or security issues, kindly follow these steps:

1. **Avoid Creating Public Issues**: Please do not discuss vulnerabilities in public to prevent malicious use.
2. **Contact Us Directly**: Send a detailed vulnerability report to [inayet@dreamsapi.com](mailto:inayet@dreamsapi.com).
3. **Response Time**: We prioritize our users' security and will address the report as soon as possible, typically within 48 hours. You'll receive an update on the reported vulnerability, and we'll work together to address the concern.

```



## Repo Structure
```json

[
  {"type":"directory","name":".","contents":[
    {"type":"directory","name":"assets","contents":[
      {"type":"file","name":"openapi310.png"}
    ]},
    {"type":"directory","name":"configuration","contents":[
      {"type":"file","name":"display_project_files.ignore.bk"},
      {"type":"file","name":"display_project_files.include.bk"}
    ]},
    {"type":"directory","name":"data","contents":[
      {"type":"file","name":"calendars.json"},
      {"type":"file","name":"calendars.yml"}
    ]},
    {"type":"directory","name":"docs","contents":[
      {"type":"file","name":"CODE_OF_CONDUCT.md"},
      {"type":"file","name":"docs-content.md"},
      {"type":"file","name":"SECURITY.md"}
    ]},
    {"type":"directory","name":"git-utils","contents":[
      {"type":"file","name":"git-utils-content.md"},
      {"type":"file","name":"useful.git-create-new-repo.py"},
      {"type":"file","name":"useful.git-update-all-branches.py"}
    ]},
    {"type":"directory","name":"src","contents":[
      {"type":"directory","name":"__pycache__","contents":[
        {"type":"file","name":"content.md"},
        {"type":"file","name":"openapi_converter.cpython-311.pyc"},
        {"type":"file","name":"src-__pycache__-content.md"}
      ]},
      {"type":"file","name":"__init__.py"},
      {"type":"file","name":"md_content_aggregator.py"},
      {"type":"file","name":"openapi_converter_main.py"},
      {"type":"file","name":"openapi_converter.py"},
      {"type":"file","name":"src-content.md"}
    ]},
    {"type":"directory","name":"utilities","contents":[
      {"type":"file","name":"organize.py"}
    ]},
    {"type":"file","name":"License"},
    {"type":"file","name":"README.md"},
    {"type":"file","name":"repodir.txt"},
    {"type":"file","name":"requirements.txt"},
    {"type":"file","name":"root-content.md"},
    {"type":"file","name":"script.log"}
  ]}
,
  {"type":"report","directories":9,"files":26}
]


```




### README.md
# Convert OpenAPI 3.0.0 to OpenAPI 3.1.0 Converter

> ![OpenAPI](assets/openapi310.png) 

## Table of Contents

- [Description](#description)
- [How to Use](#how-to-use)
- [Scripts](#scripts)
- [Configuration Files](#configuration-files)
- [Documentation](#documentation)
- [Dependencies](#dependencies)
- [Contributing](#contributing)
- [License](#license)

## Description

Welcome to the **OpenAPI 3.0.0 to OpenAPI 3.1.0 Converter** repository. This collection of tools and scripts is designed to seamlessly convert OpenAPI 3.0.0 specifications to the upgraded OpenAPI 3.1.0 format.

## How to Use

To efficiently convert your OpenAPI 3.0.0 specifications to OpenAPI 3.1.0 format, follow these steps:

### 1. `openapi_converter_main.py`

This script is the heart of the conversion process. It takes an OpenAPI 3.0.0 specification in JSON format and generates a 3.1.0 YAML specification.

Usage:

```bash
python openapi_converter_main.py [input_file.json] [output_file.yml]
```

### 2. `useful.git-create-new-repo.py`

![GitHub](https://www.vectorlogo.zone/logos/github/github-ar21.svg)

Need a new GitHub repository? This script not only initializes a repository but also sets up main, production, and development branches for your project.

Usage:

```bash
python useful.git-create-new-repo.py
```

### 3. `useful.git-update-development-production.py`

Run this then when ready to update main branch run [useful.git-update-production-main.py](useful.git-update-production-main.py) Update your development and production branches efficiently.

Usage:

```bash
python useful.git-update-development-production.py
```


### 4. `useful.git-update-production-main.py`

Keep your production and main branches up to date with this script.

Usage:

```bash
python useful.git-update-production-main.py
```

### 5. `md_content_aggregator.py`

Asynchronously scan your directory to generate a content markdown file based on the files present.

Usage:

```bash
python md_content_aggregator.py
```

## Configuration Files

### `display_project_files.ignore`

This file contains patterns of files and directories to ignore when generating documentation using the `md_content_aggregator.py` script.

### `.gitignore`

This file specifies patterns of files and directories to be ignored by Git. It helps maintain a clean repository by excluding unnecessary files and build artifacts.

### `requirements.txt`

This file lists the necessary Python packages required to run the scripts in this repository.

## Documentation

### `CODE_OF_CONDUCT.md`

This document outlines the code of conduct for contributors and users of the repository, ensuring a respectful and inclusive environment for collaboration.

### `SECURITY.md`

This document details the security policy for the repository. Learn how to report vulnerabilities and understand our commitment to promptly addressing security concerns.

Got it, here is the second part of the README content:

```markdown
## Dependencies

Install the required dependencies from `requirements.txt`:

```bash
pip install -r requirements.txt
```

## Contributing

Contributions are welcome! Please read our [Contributing Guidelines](CONTRIBUTING.md) for details on how to contribute to this project.

## License

This project is licensed under the MIT License. View the [License](LICENSE) file in the repository for more details.

## Future Plans

As we continually strive to enhance and streamline the OpenAPI conversion process, we have some exciting developments on the horizon:

### 1. Automating OpenAPI Spec Retrieval

Our upcoming feature aims to simplify the acquisition of OpenAPI specifications. We're working on an automated mechanism to fetch specs directly from websites and API endpoints. This eliminates manual downloading, providing real-time access to the most current information.

### 2. Automated Conversion and External Validation

Our focus extends beyond conversion alone. We're in the process of creating an automated pipeline that not only converts OpenAPI 3.0.0 specs to 3.1.0 but also employs external tools to validate the converted files.

### 3. Enhancing Quality with OpenAPI API Validator

In our pursuit of accurate and compliant OpenAPI specifications, we're thrilled to integrate the OpenAPI API Validator into our conversion process. This powerful validator ensures the quality, accuracy, and compliance of your converted OpenAPI specs. 

By incorporating the OpenAPI API Validator, we're taking proactive steps to eliminate errors and inconsistencies from your converted specifications. This tool empowers a seamless transition from OpenAPI 3.0.0 to 3.1.0 while maintaining the highest accuracy standards.

### Join Us
We invite you to join us on this journey towards excellence. Your feedback, ideas, and suggestions are invaluable as we enhance your OpenAPI conversion experience. Share your thoughts in the Issues section, and stay tuned for updates as we roll out these exciting features to elevate your OpenAPI conversion workflows!


## Directory Structure
```json
[
  {"type":"directory","name":"./git-utils","contents":[
    {"type":"file","name":"useful.git-create-new-repo.py"},
    {"type":"file","name":"useful.git-update-all-branches.py"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### useful.git-update-all-branches.py
```python
"""
Git Branch Update Utility

Methods:
- log_to_db: Log actions to SQLite database
- backup_database: Back up SQLite database  
- stash_changes: Stash local changes
- pop_changes: Pop stashed changes
- check_for_merge_conflicts: Check and handle merge conflicts
- handle_pull_failure: Handle pull failures
- merge_and_push: Merge source into target branch and push
- fetch_all_remote_branches: Fetch all remote branches
- ensure_correct_branch_for_action: Ensure user is on correct branch
- update_branches: Update target branches with source changes
- update_branch_with_source: Update target branch with source changes 
- get_all_branches: Get all branches in the repo
- get_all_local_branches: Get all local branches in the repo
- select_source_branch: Select source branch interactively
- select_target_branches: Select target branches interactively
- main: Main function

This script provides functionalities to:
1. Dynamically list all branches in the repository.
2. Allow users to select a source branch and multiple target branches.
3. Update the target branches with the latest changes from the source branch.  
4. Ensure users are on the correct branch before proceeding with updates.
5. Handle merge conflicts and allow users to decide how to proceed.
6. Log all actions to an SQLite database. 
7. Backup the SQLite database.
8. Fetch all remote branches to ensure the local repository is up-to-date.
"""

import os
import logging
import subprocess
import sqlite3
import shutil

DATABASE_NAME = "git_actions_log.db"

\# Set up logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()])

def log_to_db(action, message):
    with sqlite3.connect(DATABASE_NAME) as conn:
        cursor = conn.cursor()
        cursor.execute('''CREATE TABLE IF NOT EXISTS actions
                          (timestamp TEXT, action TEXT, message TEXT)''')
        cursor.execute("INSERT INTO actions (timestamp, action, message) VALUES (datetime('now'), ?, ?)",
                       (action, message))
        conn.commit()

def backup_database():
    backup_name = DATABASE_NAME.split('.')[0] + "_backup.db"
    shutil.copy(DATABASE_NAME, backup_name)
    logging.info(f"Backed up database to {backup_name}.")
    log_to_db("INFO", f"Backed up database to {backup_name}.")

def stash_changes():
    subprocess.run(["git", "stash", "push", "-m", "changes_stash_for_script"])

def pop_changes():
    stashes = subprocess.getoutput("git stash list")
    if "changes_stash_for_script" in stashes:
        subprocess.run(["git", "stash", "pop"])

def check_for_merge_conflicts():
    status = subprocess.getoutput("git status")
    if "You have unmerged paths" in status or "fix conflicts" in status:
        logging.error("You have unresolved merge conflicts.")
        print("1: Resolve conflicts manually and exit script.")
        print("2: Prioritize local changes.")
        print("3: Prioritize remote changes.")
        choice = input("Enter choice (1/2/3): ")

        if choice == '1':
            print("Resolve the conflicts manually and then run the script again.")
            exit(1)
        elif choice == '2':
            subprocess.run(["git", "checkout", "--", "."])
        elif choice == '3':
            current_branch = subprocess.getoutput("git branch --show-current")
            subprocess.run(["git", "reset", "--hard", f"origin/{current_branch}"])
        else:
            logging.warning("Invalid choice. Exiting.")
            exit(1)

def handle_pull_failure(branch_name):
    logging.error(f"Failed to pull from {branch_name}")
    user_decision = input(f"Failed to pull from {branch_name}. Do you want to proceed? (yes/no): ")
    if user_decision.lower() != 'yes':
        return False

    priority_decision = input("Which files do you want to prioritize? (local/remote): ")
    if priority_decision.lower() == 'local':
        subprocess.run(["git", "checkout", "--", "."])
    elif priority_decision.lower() == 'remote':
        subprocess.run(["git", "reset", "--hard", f"origin/{branch_name}"])
    return True

def merge_and_push(source_branch, target_branch):
    merge_result = subprocess.run(["git", "merge", source_branch, "--no-ff",
                                  "-m", f"Merging changes from {source_branch} into {target_branch}"], capture_output=True, text=True)
    if merge_result.returncode != 0:
        error_msg = f"Failed to merge {source_branch} into {target_branch}. Resolve conflicts manually."
        logging.error(error_msg + "\n" + merge_result.stderr)
        return

    push_result = subprocess.run(["git", "push", "origin", target_branch], capture_output=True, text=True)
    if push_result.returncode != 0:
        error_msg = f"Failed to push changes to {target_branch}."
        logging.error(error_msg + "\n" + push_result.stderr)
        return

    success_msg = f"Merged '{source_branch}' into '{target_branch}' and pushed changes."
    logging.info(success_msg)

def fetch_all_remote_branches():
    result = subprocess.run(["git", "fetch", "--all"], capture_output=True, text=True)
    if result.returncode != 0:
        logging.error("Failed to fetch remote branches. Please check your internet connection.")
        exit(1)
    else:
        logging.info("Successfully fetched all remote branches.")

def ensure_correct_branch_for_action(source_branch):
    current_branch = subprocess.getoutput("git branch --show-current")
    if current_branch.replace('*', '').strip() != source_branch.replace('*', '').strip():
        switch = input(f"You must be on the '{source_branch}' branch to update other branches. Switch to '{source_branch}'? (yes/no): ")
        if switch.lower() == 'yes':
            subprocess.run(["git", "checkout", source_branch])
            check_for_merge_conflicts()
        else:
            logging.warning("Operation cancelled by user.")
            exit(1)


def update_branches(source_branch, target_branches):
    """Update target branches with source changes."""
    print(f"Will merge changes from '{source_branch}' into the following branches: {', '.join(target_branches)}")
    confirmation = input("Do you want to proceed? (yes/no): ")
    if confirmation.lower() != 'yes':
        logging.info("Operation cancelled by user.")
        return

    check_for_merge_conflicts()
    stash_changes()

    for target_branch in target_branches:
        if target_branch == source_branch:
            logging.info(f"Skipping {source_branch} as it's the same as the source branch.")
            continue

        subprocess.run(["git", "checkout", target_branch])
        if not update_branch_with_source(target_branch, source_branch):
            logging.error(f"Failed to update {target_branch} with changes from {source_branch}")
            continue

    subprocess.run(["git", "checkout", source_branch])
    pop_changes()

def update_branch_with_source(target_branch, source_branch):
    pull_result = subprocess.run(["git", "pull", "origin", source_branch], capture_output=True, text=True)
    if pull_result.returncode != 0:
        logging.error(f"Failed to pull latest code from {source_branch}.")
        return False

    subprocess.run(["git", "checkout", target_branch])
    pull_target_result = subprocess.run(["git", "pull", "origin", target_branch], capture_output=True, text=True)
    if pull_target_result.returncode != 0 and not handle_pull_failure(target_branch):
        return False

    merge_and_push(source_branch, target_branch)
    return True

def get_all_branches():
    branches = subprocess.getoutput("git branch -a")
    return [branch.strip() for branch in branches.split('\n')]

def get_all_local_branches():
    branches = subprocess.getoutput("git branch")
    return [branch.strip() for branch in branches.split('\n')]

def clean_branch_name(branch):
    """Standardize and clean the branch name."""
    return branch.replace('*', '').strip().split('/')[-1]

def select_source_branch():
    """Select source branch interactively."""
    print("Select the source branch:")
    all_branches = get_all_branches()
    for idx, branch in enumerate(all_branches, start=1):
        print(f"{idx}: {branch}")

    choice = int(input(f"Enter choice (1 to {len(all_branches)}): "))
    if choice < 1 or choice > len(all_branches):
        logging.error("Invalid choice.")
        exit(2)

    source_branch = clean_branch_name(all_branches[choice - 1])
    return source_branch

def select_target_branches():
    """Select target branches interactively."""
    print("Select the target branches:")
    
    all_local_branches = get_all_local_branches()
    for idx, branch in enumerate(all_local_branches, start=1):
        print(f"{idx}: {branch}")

    choices = list(map(int, input("Enter choices (comma separated): ").split(',')))
    target_branches = [all_local_branches[choice - 1].replace('*', '').strip() for choice in choices]
    return target_branches



def handle_unstaged_changes():
    """Handle any unstaged changes in the repo."""
    status = subprocess.getoutput("git status")
    if "Changes not staged for commit:" in status:
        print("\nThere are some unstaged changes in your repository. Here's what changed:\n")
        os.system("git diff")
        
        \# Extract filenames here, outside of the choice blocks.
        filenames = [line.split(":")[1].strip() for line in status.split("\n") if "modified:" in line]

        print("\nOptions:")
        print("1: Stage and commit the changes.")
        print("2: Discard the changes.")
        print("3: Exit and handle the changes manually.")
        
        choice = input("\nEnter your choice (1/2/3): ")
        
        if choice == '1':
            for filename in filenames:
                subprocess.run(["git", "add", filename])
            commit_message = input("Enter commit message: ")
            subprocess.run(["git", "commit", "-m", commit_message])
            print("Changes have been staged and committed.")
        
        elif choice == '2':
            for filename in filenames:
                subprocess.run(["git", "checkout", "--", filename])
            print("Changes have been discarded.")
        
        elif choice == '3':
            print("Exiting. You can handle the changes manually.")
            exit(1)



def main():
    logging.info("Git Branch Update Utility")
    
    fetch_all_remote_branches()
    backup_database()
    
    source_branch = select_source_branch()
    ensure_correct_branch_for_action(source_branch)
    
    target_branches = select_target_branches()
    confirm = input(f"Will merge changes from '{source_branch}' into the following branches: {', '.join(target_branches)}\nDo you want to proceed? (yes/no): ")
    
    if confirm.lower() != 'yes':
        logging.warning("Operation cancelled by user.")
        exit(1)
    
    update_branches(source_branch, target_branches)
    handle_unstaged_changes()

if __name__ == "__main__":
    main()
```


### useful.git-create-new-repo.py
```python
\# Filename: useful.git\-create\-new\-repo.py
\# This script helps create a new Git repository

import os
import logging
import subprocess

\# Set up logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()])

def initialize_and_setup_repo():
    \# Set the absolute path for the current directory
    directory_path = os.path.abspath('.')
    logging.info(f"Directory path: {directory_path}")
    
    \# Get the last part of the directory path
    repo_name = os.path.basename(directory_path)
    logging.info(f"Repo name: {repo_name}")

    \# Check if the directory already has a Git repo
    if os.path.isdir(os.path.join(directory_path, ".git")):
        logging.info("Directory already has a git repo")
        return

    \# Create a new GitHub repository with the current directory name
    subprocess.run(["gh", "repo", "create", repo_name, "--private", "-y"])
    logging.info(f"GitHub repository '{repo_name}' created successfully!")

    \# Initialize a new Git repo
    subprocess.run(["git", "init", "--quiet"])

    \# Add all of the files to the repo
    subprocess.run(["git", "add", "*"])

    \# Commit the changes to the repo
    subprocess.run(["git", "commit", "-m", "Initial commit on main branch"])

    \# Add the remote origin
    remote_url = f"https://github.com/inayet/{repo_name}.git"
    subprocess.run(["git", "remote", "add", "origin", remote_url])

    \# Push the main branch to the new GitHub repository
    subprocess.run(["git", "push", "-u", "origin", "main"])

    \# Create the 'production' branch, commit, and push
    subprocess.run(["git", "checkout", "-b", "production"])
    subprocess.run(["git", "push", "-u", "origin", "production"])
    logging.info("Created and pushed 'production' branch.")

    \# Switch back to main to create the 'development' branch, commit, and push
    subprocess.run(["git", "checkout", "main"])
    subprocess.run(["git", "checkout", "-b", "development"])
    subprocess.run(["git", "push", "-u", "origin", "development"])
    logging.info("Created and pushed 'development' branch.")

    \# Log the success message
    logging.info("Repo setup complete!")

if __name__ == "__main__":
    initialize_and_setup_repo()

```

## Directory Structure
```json
[
  {"type":"directory","name":"./src","contents":[
    {"type":"directory","name":"__pycache__","contents":[
      {"type":"file","name":"content.md"},
      {"type":"file","name":"openapi_converter.cpython-311.pyc"},
      {"type":"file","name":"src-__pycache__-content.md"}
    ]},
    {"type":"file","name":"__init__.py"},
    {"type":"file","name":"md_content_aggregator.py"},
    {"type":"file","name":"openapi_converter_main.py"},
    {"type":"file","name":"openapi_converter.py"}
  ]}
,
  {"type":"report","directories":2,"files":7}
]

```


### __init__.py
```python

```


### openapi_converter_main.py
```python
\# Filename is openapi\_converter\_main.py
\# This file contains the main function to convert an OpenAPI 3.0 spec to 3.1

import argparse
import openapi_converter as converter 
import yaml
import os

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('input_file')
    parser.add_argument('output_file', nargs='?', default=None)
    args = parser.parse_args()

    if args.output_file is None:
        base_name = os.path.splitext(args.input_file)[0]  # Get the name without extension
        args.output_file = os.path.join(os.getcwd(), f"{base_name}.yml")

    if not os.path.exists(args.input_file):
        raise FileNotFoundError(f"Input file '{args.input_file}' does not exist.")

    with open(args.input_file, 'r') as f:
        openapi_dict = yaml.safe_load(f.read())  # <-- Fixed here

    try:
        converted_spec = converter.convert_openapi(openapi_dict)
        with open(args.output_file, 'w') as f:
            f.write(converted_spec)
        print(f"Converted spec saved to {args.output_file}")
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == '__main__':
    main()

```


### openapi_converter.py
```python
\# Filename openapi\_converter.py
\# This module contains functions to convert an OpenAPI 3.0 spec to 3.1

import yaml
import logging
from collections import OrderedDict

logging.basicConfig(level=logging.INFO)

def convert_openapi(openapi_dict):
    \# Input validation

    validate_required_fields(openapi_dict)
    validate_openapi_version(openapi_dict, versions=["3.0.0", "3.1.0"])
    check_incompatible_inputs(openapi_dict, incompatible_keys=["securityDefinitions"])

    \# Retain operation details

    for path in openapi_dict['paths'].values():
        for operation in path.values():
            if 'description' in operation:
                operation['x-original-description'] = operation['description']
            if 'operationId' in operation:
                operation['x-original-operationId'] = operation['operationId']

    \# Retain schema details

    for schema in openapi_dict['components']['schemas'].values():
        if 'description' in schema:
            schema['x-original-description'] = schema['description']

    \# Update to OpenAPI version 3.1.0

    openapi_dict['openapi'] = "3.1.0"

    \# Security schemes

    security_schemes = {}

    if 'securityDefinitions' in openapi_dict:
        logging.warning(
            f"'securityDefinitions' found - converting to 'securitySchemes'. "
            "This key is deprecated in OpenAPI 3.1.0 and should be replaced with 'securitySchemes'."
        )
        security_definitions = openapi_dict.pop('securityDefinitions')
        for def_name, definition in security_definitions.items():
            scheme = {
                'type': definition.get('type', 'http'),
                'scheme': definition.get('scheme', 'bearer')
            }
            if 'bearerFormat' in definition:
                scheme['bearerFormat'] = definition['bearerFormat']
            if 'description' in definition:
                scheme['description'] = definition['description']
            security_schemes[def_name] = scheme

    openapi_dict['components']['securitySchemes'] = security_schemes

    \# YAML conversion

    yaml_string = yaml.dump(openapi_dict, sort_keys=True)

    return yaml_string

\# Input validation functions

def validate_required_fields(openapi_dict):
    required_fields = ['openapi', 'info', 'paths']
    for field in required_fields:
        if field not in openapi_dict:
            raise Exception(f"Field '{field}' is required")

def validate_openapi_version(openapi_dict, versions=["3.0.0", "3.1.0"]):
    if openapi_dict['openapi'] not in versions:
        raise Exception(
            f"Input version must be one of {versions}. Found {openapi_dict['openapi']}"
        )

def check_incompatible_inputs(openapi_dict, incompatible_keys=['securityDefinitions']):
    for key in incompatible_keys:
        if key in openapi_dict:
            raise Exception(f"Input contains deprecated key '{key}'.")

```


### md_content_aggregator.py
```python
'''
Name: md_content_aggregator.py

Purpose:
The MD Content Aggregator is designed to scan a directory structure, extracting content from files that match specific criteria, and generate a content.md file for each directory and an all-contents.md file in the root directory. The generated files contain aggregated content from the scanned files, appropriately formatted in Markdown.

Methods and Functionalities:
- escape_markdown_characters_in_python_code(code: str) -> str:
    Escapes markdown special characters in a given string containing Python code to ensure they're not interpreted as markdown formatting.

- get_repo_structure(directory: str) -> str:
    Uses the tree command to generate a JSON representation of the directory structure.

- should_include(file_path: str, is_dir: bool = False) -> bool:
    Determines if a file or directory should be included based on specified patterns and extensions.

- directory_structure(directory: str) -> str:
    Retrieve the structure of a specific directory in JSON format.

- generate_filename(directory: str) -> str:
    Generates the filename for the content.md file based on the directory structure.

- generate_md_files(directory: str) -> None:
    Asynchronously processes a directory to identify files for aggregation and generate a content.md file.

- combine_md_files() -> None:
    Generates the all-contents.md file in the root directory by combining all the content.md files.

- process_directory(directory: str) -> None:
    Recursively processes directories to generate content.md files.

- main() -> None:
    The main asynchronous function that initiates the content aggregation process.

Configuration and Constants:
- EXCLUDED_EXTENSIONS: File extensions that are to be ignored.
- EXCLUSIVE_EXTENSION: Patterns and directories that the content aggregation process should exclusively focus on.
- Logging: Captures information, warnings, and error messages to script.log.

How to Use:
1. Ensure the script has access to the directories you wish to scan.
2. Run the script.
3. Once complete, find a content.md file in each directory and an all-contents.md file in the root directory.

Note: The script uses asynchronous file operations for improved performance with a large number of files or large-sized files. Ensure required libraries are installed.
'''

import os
import asyncio
import aiofiles
import logging
import fnmatch
import subprocess
import re


logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()])

EXCLUDED_EXTENSIONS = ['.db', '.log', '.sh', '.pyc', 'content.md']
EXCLUSIVE_EXTENSION = ['*.py', '*.md', 'docs/*', 'git-utils/*', 'src/*', '.']

added_content = set()


def escape_markdown_characters_in_python_code(code: str) -> str:
    """Escape markdown special characters within Python code."""
    lines = code.split('\n')
    escaped_lines = []
    for line in lines:
        if line.strip().startswith("#"):
            line = line.replace("#", r"\#")
            line = line.replace("*", r"\*")
            line = line.replace("_", r"\_")
            line = line.replace("[", r"\[")
            line = line.replace("]", r"\]")
            line = line.replace("(", r"\(")
            line = line.replace(")", r"\)")
            line = line.replace(">", r"\>")
            line = line.replace("-", r"\-")
        escaped_lines.append(line)
    return '\n'.join(escaped_lines)

def get_repo_structure(directory):
    """Retrieve the repository structure in JSON format."""
    try:
        result = subprocess.run(['tree', '--dirsfirst', '-J', directory],
                                capture_output=True, text=True, check=True)
        return result.stdout
    except subprocess.CalledProcessError as e:
        logging.error(f"Error getting repo structure: {e}")
        return ""

def should_include(file_path, is_dir=False):
    """
    Determine if a file or directory should be included based on exclusive and excluded patterns.
    """
    if is_dir:
        \# Explicitly check for directories using string methods
        dir_checks = ['docs', 'git-utils', 'src']
        return any(check in file_path for check in dir_checks)

    if any(fnmatch.fnmatch(file_path, pattern) for pattern in EXCLUDED_EXTENSIONS):
        return False

    return any(fnmatch.fnmatch(file_path, pattern) for pattern in EXCLUSIVE_EXTENSION)



def directory_structure(directory):
    """Retrieve the structure of a specific directory in JSON format."""
    try:
        result = subprocess.run(['tree', '--dirsfirst', '-J', directory],
                                capture_output=True, text=True, check=True)
        return result.stdout
    except subprocess.CalledProcessError as e:
        logging.error(f"Error getting directory structure: {e}")
        return ""



def generate_filename(directory):
    """Generate filename based on the directory structure."""
    if directory == ".":
        return "root-content.md"
    else:
        parts = [part for part in directory.split(os.sep) if part != "."]
        return "-".join(parts) + "-content.md"

async def generate_md_files(directory):
    """Generate content.md files for the specified directory."""
    logging.info(f"Processing directory: {directory}")
    content_filepath = os.path.join(directory, generate_filename(directory))
    \# Delete the existing content.md file if it exists
    if os.path.exists(content_filepath):
        os.remove(content_filepath)
    toc_content = "## Table of Contents\n"
    dir_structure = f"\n\n## Directory Structure\n```json\n{directory_structure(directory)}\n```\n\n"
    file_content_list = []

    for entry in os.scandir(directory):
        if entry.is_file() and should_include(entry.path) and entry.name != content_filepath:
            try:
                async with aiofiles.open(entry.path, 'r', encoding='utf-8') as f:
                    file_content = await f.read()

                if file_content in added_content:
                    continue
                added_content.add(file_content)

                toc_content += f"- [{entry.name}](#{entry.name.replace('.', '-')})\n"

                if entry.name.endswith('.py'):
                    file_content = escape_markdown_characters_in_python_code(file_content)
                    file_content_list.append(f"\n### {entry.name}\n```python\n{file_content}\n```\n")
                elif entry.name.endswith('.md'):
                    file_content_list.append(f"\n### {entry.name}\n{file_content}\n")
            except UnicodeDecodeError:
                logging.warning(f"Unable to read file {entry.name} as it's not in UTF-8 encoding. Skipping.")

    async with aiofiles.open(content_filepath, 'w') as f:
        await f.write(toc_content + dir_structure + '\n'.join(file_content_list))


def combine_md_files():
    combined_content_sections = ["# Project Documentation\n\n", "## Table of Contents\n"]
    \# Delete the existing all\-contents.md file if it exists
    if os.path.exists("all-contents.md"):
        os.remove("all-contents.md")
    toc_links = set()

    for directory, _, filenames in os.walk("."):
        content_md_name = generate_filename(directory)
        content_md_path = os.path.join(directory, content_md_name)
        if content_md_name in filenames:
            logging.info(f"Reading {content_md_path}")
            with open(content_md_path, 'r', encoding='utf-8') as f:
                content = f.read()

            sections = content.split("\n## ")
            toc_section = sections[0]
            toc_links.update(re.findall(r"- \[.*?\]\(.*?\)", toc_section))
            for section in sections[1:]:
                combined_content_sections.append("## " + section)

    combined_content_sections.insert(2, "\n".join(toc_links))
    combined_content_sections.append("\n\n## Repo Structure\n```json\n")
    combined_content_sections.append(get_repo_structure("."))
    combined_content_sections.append("\n```\n\n")

    with open("all-contents.md", 'w', encoding='utf-8') as f:
        f.write('\n'.join(combined_content_sections))



async def process_directory(directory):
    """Process a directory and its subdirectories to generate content.md files."""
    logging.info(f"Checking directory: {directory}")
    await generate_md_files(directory)

    for entry in os.scandir(directory):
        if entry.is_dir() and should_include(entry.path, is_dir=True):
            await process_directory(entry.path)

async def main():
    """Main asynchronous function to start content aggregation."""
    global added_content
    added_content = set()  # Reset the set
    await process_directory(".")
    combine_md_files()

if __name__ == "__main__":
    asyncio.run(main())
```

## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```



## Directory Structure
```json
[
  {"type":"directory","name":"./docs","contents":[
    {"type":"file","name":"CODE_OF_CONDUCT.md"},
    {"type":"file","name":"SECURITY.md"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### CODE_OF_CONDUCT.md
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
inayet@dreamsapi.com.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.


### SECURITY.md
### SECURITY.md

```markdown
# Security Policy

![Security](https://www.vectorlogo.zone/logos/snykio/snykio-ar21.svg)

## Supported Versions

Currently, we support the following versions of "Convert OpenAPI 3.0.0 specs to OpenAPI 3.1.0" with security updates:

| Version | Supported          |
| ------- | ------------------ |
| 1.2.x   | :white_check_mark: |
| 1.1.x   | :white_check_mark: |
| 1.0.x   | :x:                |

## Reporting a Vulnerability

If you discover any vulnerabilities or security issues, kindly follow these steps:

1. **Avoid Creating Public Issues**: Please do not discuss vulnerabilities in public to prevent malicious use.
2. **Contact Us Directly**: Send a detailed vulnerability report to [inayet@dreamsapi.com](mailto:inayet@dreamsapi.com).
3. **Response Time**: We prioritize our users' security and will address the report as soon as possible, typically within 48 hours. You'll receive an update on the reported vulnerability, and we'll work together to address the concern.

```



## Repo Structure
```json

[
  {"type":"directory","name":".","contents":[
    {"type":"directory","name":"assets","contents":[
      {"type":"file","name":"openapi310.png"}
    ]},
    {"type":"directory","name":"configuration","contents":[
      {"type":"file","name":"display_project_files.ignore.bk"},
      {"type":"file","name":"display_project_files.include.bk"}
    ]},
    {"type":"directory","name":"data","contents":[
      {"type":"file","name":"calendars.json"},
      {"type":"file","name":"calendars.yml"}
    ]},
    {"type":"directory","name":"docs","contents":[
      {"type":"file","name":"CODE_OF_CONDUCT.md"},
      {"type":"file","name":"docs-content.md"},
      {"type":"file","name":"SECURITY.md"}
    ]},
    {"type":"directory","name":"git-utils","contents":[
      {"type":"file","name":"git-utils-content.md"},
      {"type":"file","name":"useful.git-create-new-repo.py"},
      {"type":"file","name":"useful.git-update-all-branches.py"}
    ]},
    {"type":"directory","name":"src","contents":[
      {"type":"directory","name":"__pycache__","contents":[
        {"type":"file","name":"content.md"},
        {"type":"file","name":"openapi_converter.cpython-311.pyc"},
        {"type":"file","name":"src-__pycache__-content.md"}
      ]},
      {"type":"file","name":"__init__.py"},
      {"type":"file","name":"md_content_aggregator.py"},
      {"type":"file","name":"openapi_converter_main.py"},
      {"type":"file","name":"openapi_converter.py"},
      {"type":"file","name":"src-content.md"}
    ]},
    {"type":"directory","name":"utilities","contents":[
      {"type":"file","name":"organize.py"}
    ]},
    {"type":"file","name":"License"},
    {"type":"file","name":"README.md"},
    {"type":"file","name":"repodir.txt"},
    {"type":"file","name":"requirements.txt"},
    {"type":"file","name":"root-content.md"},
    {"type":"file","name":"script.log"}
  ]}
,
  {"type":"report","directories":9,"files":26}
]


```




### README.md
# Convert OpenAPI 3.0.0 to OpenAPI 3.1.0 Converter

> ![OpenAPI](assets/openapi310.png) 

## Table of Contents

- [Description](#description)
- [How to Use](#how-to-use)
- [Scripts](#scripts)
- [Configuration Files](#configuration-files)
- [Documentation](#documentation)
- [Dependencies](#dependencies)
- [Contributing](#contributing)
- [License](#license)

## Description

Welcome to the **OpenAPI 3.0.0 to OpenAPI 3.1.0 Converter** repository. This collection of tools and scripts is designed to seamlessly convert OpenAPI 3.0.0 specifications to the upgraded OpenAPI 3.1.0 format.

## How to Use

To efficiently convert your OpenAPI 3.0.0 specifications to OpenAPI 3.1.0 format, follow these steps:

### 1. `openapi_converter_main.py`

This script is the heart of the conversion process. It takes an OpenAPI 3.0.0 specification in JSON format and generates a 3.1.0 YAML specification.

Usage:

```bash
python openapi_converter_main.py [input_file.json] [output_file.yml]
```

### 2. `useful.git-create-new-repo.py`

![GitHub](https://www.vectorlogo.zone/logos/github/github-ar21.svg)

Need a new GitHub repository? This script not only initializes a repository but also sets up main, production, and development branches for your project.

Usage:

```bash
python useful.git-create-new-repo.py
```

### 3. `useful.git-update-development-production.py`

Run this then when ready to update main branch run [useful.git-update-production-main.py](useful.git-update-production-main.py) Update your development and production branches efficiently.

Usage:

```bash
python useful.git-update-development-production.py
```


### 4. `useful.git-update-production-main.py`

Keep your production and main branches up to date with this script.

Usage:

```bash
python useful.git-update-production-main.py
```

### 5. `md_content_aggregator.py`

Asynchronously scan your directory to generate a content markdown file based on the files present.

Usage:

```bash
python md_content_aggregator.py
```

## Configuration Files

### `display_project_files.ignore`

This file contains patterns of files and directories to ignore when generating documentation using the `md_content_aggregator.py` script.

### `.gitignore`

This file specifies patterns of files and directories to be ignored by Git. It helps maintain a clean repository by excluding unnecessary files and build artifacts.

### `requirements.txt`

This file lists the necessary Python packages required to run the scripts in this repository.

## Documentation

### `CODE_OF_CONDUCT.md`

This document outlines the code of conduct for contributors and users of the repository, ensuring a respectful and inclusive environment for collaboration.

### `SECURITY.md`

This document details the security policy for the repository. Learn how to report vulnerabilities and understand our commitment to promptly addressing security concerns.

Got it, here is the second part of the README content:

```markdown
## Dependencies

Install the required dependencies from `requirements.txt`:

```bash
pip install -r requirements.txt
```

## Contributing

Contributions are welcome! Please read our [Contributing Guidelines](CONTRIBUTING.md) for details on how to contribute to this project.

## License

This project is licensed under the MIT License. View the [License](LICENSE) file in the repository for more details.

## Future Plans

As we continually strive to enhance and streamline the OpenAPI conversion process, we have some exciting developments on the horizon:

### 1. Automating OpenAPI Spec Retrieval

Our upcoming feature aims to simplify the acquisition of OpenAPI specifications. We're working on an automated mechanism to fetch specs directly from websites and API endpoints. This eliminates manual downloading, providing real-time access to the most current information.

### 2. Automated Conversion and External Validation

Our focus extends beyond conversion alone. We're in the process of creating an automated pipeline that not only converts OpenAPI 3.0.0 specs to 3.1.0 but also employs external tools to validate the converted files.

### 3. Enhancing Quality with OpenAPI API Validator

In our pursuit of accurate and compliant OpenAPI specifications, we're thrilled to integrate the OpenAPI API Validator into our conversion process. This powerful validator ensures the quality, accuracy, and compliance of your converted OpenAPI specs. 

By incorporating the OpenAPI API Validator, we're taking proactive steps to eliminate errors and inconsistencies from your converted specifications. This tool empowers a seamless transition from OpenAPI 3.0.0 to 3.1.0 while maintaining the highest accuracy standards.

### Join Us
We invite you to join us on this journey towards excellence. Your feedback, ideas, and suggestions are invaluable as we enhance your OpenAPI conversion experience. Share your thoughts in the Issues section, and stay tuned for updates as we roll out these exciting features to elevate your OpenAPI conversion workflows!


## Directory Structure
```json
[
  {"type":"directory","name":"./git-utils","contents":[
    {"type":"file","name":"useful.git-create-new-repo.py"},
    {"type":"file","name":"useful.git-update-all-branches.py"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### useful.git-update-all-branches.py
```python
"""
Git Branch Update Utility

Methods:
- log_to_db: Log actions to SQLite database
- backup_database: Back up SQLite database  
- stash_changes: Stash local changes
- pop_changes: Pop stashed changes
- check_for_merge_conflicts: Check and handle merge conflicts
- handle_pull_failure: Handle pull failures
- merge_and_push: Merge source into target branch and push
- fetch_all_remote_branches: Fetch all remote branches
- ensure_correct_branch_for_action: Ensure user is on correct branch
- update_branches: Update target branches with source changes
- update_branch_with_source: Update target branch with source changes 
- get_all_branches: Get all branches in the repo
- get_all_local_branches: Get all local branches in the repo
- select_source_branch: Select source branch interactively
- select_target_branches: Select target branches interactively
- main: Main function

This script provides functionalities to:
1. Dynamically list all branches in the repository.
2. Allow users to select a source branch and multiple target branches.
3. Update the target branches with the latest changes from the source branch.  
4. Ensure users are on the correct branch before proceeding with updates.
5. Handle merge conflicts and allow users to decide how to proceed.
6. Log all actions to an SQLite database. 
7. Backup the SQLite database.
8. Fetch all remote branches to ensure the local repository is up-to-date.
"""

import os
import logging
import subprocess
import sqlite3
import shutil

DATABASE_NAME = "git_actions_log.db"

\# Set up logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()])

def log_to_db(action, message):
    with sqlite3.connect(DATABASE_NAME) as conn:
        cursor = conn.cursor()
        cursor.execute('''CREATE TABLE IF NOT EXISTS actions
                          (timestamp TEXT, action TEXT, message TEXT)''')
        cursor.execute("INSERT INTO actions (timestamp, action, message) VALUES (datetime('now'), ?, ?)",
                       (action, message))
        conn.commit()

def backup_database():
    backup_name = DATABASE_NAME.split('.')[0] + "_backup.db"
    shutil.copy(DATABASE_NAME, backup_name)
    logging.info(f"Backed up database to {backup_name}.")
    log_to_db("INFO", f"Backed up database to {backup_name}.")

def stash_changes():
    subprocess.run(["git", "stash", "push", "-m", "changes_stash_for_script"])

def pop_changes():
    stashes = subprocess.getoutput("git stash list")
    if "changes_stash_for_script" in stashes:
        subprocess.run(["git", "stash", "pop"])

def check_for_merge_conflicts():
    status = subprocess.getoutput("git status")
    if "You have unmerged paths" in status or "fix conflicts" in status:
        logging.error("You have unresolved merge conflicts.")
        print("1: Resolve conflicts manually and exit script.")
        print("2: Prioritize local changes.")
        print("3: Prioritize remote changes.")
        choice = input("Enter choice (1/2/3): ")

        if choice == '1':
            print("Resolve the conflicts manually and then run the script again.")
            exit(1)
        elif choice == '2':
            subprocess.run(["git", "checkout", "--", "."])
        elif choice == '3':
            current_branch = subprocess.getoutput("git branch --show-current")
            subprocess.run(["git", "reset", "--hard", f"origin/{current_branch}"])
        else:
            logging.warning("Invalid choice. Exiting.")
            exit(1)

def handle_pull_failure(branch_name):
    logging.error(f"Failed to pull from {branch_name}")
    user_decision = input(f"Failed to pull from {branch_name}. Do you want to proceed? (yes/no): ")
    if user_decision.lower() != 'yes':
        return False

    priority_decision = input("Which files do you want to prioritize? (local/remote): ")
    if priority_decision.lower() == 'local':
        subprocess.run(["git", "checkout", "--", "."])
    elif priority_decision.lower() == 'remote':
        subprocess.run(["git", "reset", "--hard", f"origin/{branch_name}"])
    return True

def merge_and_push(source_branch, target_branch):
    merge_result = subprocess.run(["git", "merge", source_branch, "--no-ff",
                                  "-m", f"Merging changes from {source_branch} into {target_branch}"], capture_output=True, text=True)
    if merge_result.returncode != 0:
        error_msg = f"Failed to merge {source_branch} into {target_branch}. Resolve conflicts manually."
        logging.error(error_msg + "\n" + merge_result.stderr)
        return

    push_result = subprocess.run(["git", "push", "origin", target_branch], capture_output=True, text=True)
    if push_result.returncode != 0:
        error_msg = f"Failed to push changes to {target_branch}."
        logging.error(error_msg + "\n" + push_result.stderr)
        return

    success_msg = f"Merged '{source_branch}' into '{target_branch}' and pushed changes."
    logging.info(success_msg)

def fetch_all_remote_branches():
    result = subprocess.run(["git", "fetch", "--all"], capture_output=True, text=True)
    if result.returncode != 0:
        logging.error("Failed to fetch remote branches. Please check your internet connection.")
        exit(1)
    else:
        logging.info("Successfully fetched all remote branches.")

def ensure_correct_branch_for_action(source_branch):
    current_branch = subprocess.getoutput("git branch --show-current")
    if current_branch.replace('*', '').strip() != source_branch.replace('*', '').strip():
        switch = input(f"You must be on the '{source_branch}' branch to update other branches. Switch to '{source_branch}'? (yes/no): ")
        if switch.lower() == 'yes':
            subprocess.run(["git", "checkout", source_branch])
            check_for_merge_conflicts()
        else:
            logging.warning("Operation cancelled by user.")
            exit(1)


def update_branches(source_branch, target_branches):
    """Update target branches with source changes."""
    print(f"Will merge changes from '{source_branch}' into the following branches: {', '.join(target_branches)}")
    confirmation = input("Do you want to proceed? (yes/no): ")
    if confirmation.lower() != 'yes':
        logging.info("Operation cancelled by user.")
        return

    check_for_merge_conflicts()
    stash_changes()

    for target_branch in target_branches:
        if target_branch == source_branch:
            logging.info(f"Skipping {source_branch} as it's the same as the source branch.")
            continue

        subprocess.run(["git", "checkout", target_branch])
        if not update_branch_with_source(target_branch, source_branch):
            logging.error(f"Failed to update {target_branch} with changes from {source_branch}")
            continue

    subprocess.run(["git", "checkout", source_branch])
    pop_changes()

def update_branch_with_source(target_branch, source_branch):
    pull_result = subprocess.run(["git", "pull", "origin", source_branch], capture_output=True, text=True)
    if pull_result.returncode != 0:
        logging.error(f"Failed to pull latest code from {source_branch}.")
        return False

    subprocess.run(["git", "checkout", target_branch])
    pull_target_result = subprocess.run(["git", "pull", "origin", target_branch], capture_output=True, text=True)
    if pull_target_result.returncode != 0 and not handle_pull_failure(target_branch):
        return False

    merge_and_push(source_branch, target_branch)
    return True

def get_all_branches():
    branches = subprocess.getoutput("git branch -a")
    return [branch.strip() for branch in branches.split('\n')]

def get_all_local_branches():
    branches = subprocess.getoutput("git branch")
    return [branch.strip() for branch in branches.split('\n')]

def clean_branch_name(branch):
    """Standardize and clean the branch name."""
    return branch.replace('*', '').strip().split('/')[-1]

def select_source_branch():
    """Select source branch interactively."""
    print("Select the source branch:")
    all_branches = get_all_branches()
    for idx, branch in enumerate(all_branches, start=1):
        print(f"{idx}: {branch}")

    choice = int(input(f"Enter choice (1 to {len(all_branches)}): "))
    if choice < 1 or choice > len(all_branches):
        logging.error("Invalid choice.")
        exit(2)

    source_branch = clean_branch_name(all_branches[choice - 1])
    return source_branch

def select_target_branches():
    """Select target branches interactively."""
    print("Select the target branches:")
    
    all_local_branches = get_all_local_branches()
    for idx, branch in enumerate(all_local_branches, start=1):
        print(f"{idx}: {branch}")

    choices = list(map(int, input("Enter choices (comma separated): ").split(',')))
    target_branches = [all_local_branches[choice - 1].replace('*', '').strip() for choice in choices]
    return target_branches



def handle_unstaged_changes():
    """Handle any unstaged changes in the repo."""
    status = subprocess.getoutput("git status")
    if "Changes not staged for commit:" in status:
        print("\nThere are some unstaged changes in your repository. Here's what changed:\n")
        os.system("git diff")
        
        \# Extract filenames here, outside of the choice blocks.
        filenames = [line.split(":")[1].strip() for line in status.split("\n") if "modified:" in line]

        print("\nOptions:")
        print("1: Stage and commit the changes.")
        print("2: Discard the changes.")
        print("3: Exit and handle the changes manually.")
        
        choice = input("\nEnter your choice (1/2/3): ")
        
        if choice == '1':
            for filename in filenames:
                subprocess.run(["git", "add", filename])
            commit_message = input("Enter commit message: ")
            subprocess.run(["git", "commit", "-m", commit_message])
            print("Changes have been staged and committed.")
        
        elif choice == '2':
            for filename in filenames:
                subprocess.run(["git", "checkout", "--", filename])
            print("Changes have been discarded.")
        
        elif choice == '3':
            print("Exiting. You can handle the changes manually.")
            exit(1)



def main():
    logging.info("Git Branch Update Utility")
    
    fetch_all_remote_branches()
    backup_database()
    
    source_branch = select_source_branch()
    ensure_correct_branch_for_action(source_branch)
    
    target_branches = select_target_branches()
    confirm = input(f"Will merge changes from '{source_branch}' into the following branches: {', '.join(target_branches)}\nDo you want to proceed? (yes/no): ")
    
    if confirm.lower() != 'yes':
        logging.warning("Operation cancelled by user.")
        exit(1)
    
    update_branches(source_branch, target_branches)
    handle_unstaged_changes()

if __name__ == "__main__":
    main()
```


### useful.git-create-new-repo.py
```python
\# Filename: useful.git\-create\-new\-repo.py
\# This script helps create a new Git repository

import os
import logging
import subprocess

\# Set up logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()])

def initialize_and_setup_repo():
    \# Set the absolute path for the current directory
    directory_path = os.path.abspath('.')
    logging.info(f"Directory path: {directory_path}")
    
    \# Get the last part of the directory path
    repo_name = os.path.basename(directory_path)
    logging.info(f"Repo name: {repo_name}")

    \# Check if the directory already has a Git repo
    if os.path.isdir(os.path.join(directory_path, ".git")):
        logging.info("Directory already has a git repo")
        return

    \# Create a new GitHub repository with the current directory name
    subprocess.run(["gh", "repo", "create", repo_name, "--private", "-y"])
    logging.info(f"GitHub repository '{repo_name}' created successfully!")

    \# Initialize a new Git repo
    subprocess.run(["git", "init", "--quiet"])

    \# Add all of the files to the repo
    subprocess.run(["git", "add", "*"])

    \# Commit the changes to the repo
    subprocess.run(["git", "commit", "-m", "Initial commit on main branch"])

    \# Add the remote origin
    remote_url = f"https://github.com/inayet/{repo_name}.git"
    subprocess.run(["git", "remote", "add", "origin", remote_url])

    \# Push the main branch to the new GitHub repository
    subprocess.run(["git", "push", "-u", "origin", "main"])

    \# Create the 'production' branch, commit, and push
    subprocess.run(["git", "checkout", "-b", "production"])
    subprocess.run(["git", "push", "-u", "origin", "production"])
    logging.info("Created and pushed 'production' branch.")

    \# Switch back to main to create the 'development' branch, commit, and push
    subprocess.run(["git", "checkout", "main"])
    subprocess.run(["git", "checkout", "-b", "development"])
    subprocess.run(["git", "push", "-u", "origin", "development"])
    logging.info("Created and pushed 'development' branch.")

    \# Log the success message
    logging.info("Repo setup complete!")

if __name__ == "__main__":
    initialize_and_setup_repo()

```

## Directory Structure
```json
[
  {"type":"directory","name":"./src","contents":[
    {"type":"directory","name":"__pycache__","contents":[
      {"type":"file","name":"content.md"},
      {"type":"file","name":"openapi_converter.cpython-311.pyc"},
      {"type":"file","name":"src-__pycache__-content.md"}
    ]},
    {"type":"file","name":"__init__.py"},
    {"type":"file","name":"md_content_aggregator.py"},
    {"type":"file","name":"openapi_converter_main.py"},
    {"type":"file","name":"openapi_converter.py"}
  ]}
,
  {"type":"report","directories":2,"files":7}
]

```


### __init__.py
```python

```


### openapi_converter_main.py
```python
\# Filename is openapi\_converter\_main.py
\# This file contains the main function to convert an OpenAPI 3.0 spec to 3.1

import argparse
import openapi_converter as converter 
import yaml
import os

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('input_file')
    parser.add_argument('output_file', nargs='?', default=None)
    args = parser.parse_args()

    if args.output_file is None:
        base_name = os.path.splitext(args.input_file)[0]  # Get the name without extension
        args.output_file = os.path.join(os.getcwd(), f"{base_name}.yml")

    if not os.path.exists(args.input_file):
        raise FileNotFoundError(f"Input file '{args.input_file}' does not exist.")

    with open(args.input_file, 'r') as f:
        openapi_dict = yaml.safe_load(f.read())  # <-- Fixed here

    try:
        converted_spec = converter.convert_openapi(openapi_dict)
        with open(args.output_file, 'w') as f:
            f.write(converted_spec)
        print(f"Converted spec saved to {args.output_file}")
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == '__main__':
    main()

```


### openapi_converter.py
```python
\# Filename openapi\_converter.py
\# This module contains functions to convert an OpenAPI 3.0 spec to 3.1

import yaml
import logging
from collections import OrderedDict

logging.basicConfig(level=logging.INFO)

def convert_openapi(openapi_dict):
    \# Input validation

    validate_required_fields(openapi_dict)
    validate_openapi_version(openapi_dict, versions=["3.0.0", "3.1.0"])
    check_incompatible_inputs(openapi_dict, incompatible_keys=["securityDefinitions"])

    \# Retain operation details

    for path in openapi_dict['paths'].values():
        for operation in path.values():
            if 'description' in operation:
                operation['x-original-description'] = operation['description']
            if 'operationId' in operation:
                operation['x-original-operationId'] = operation['operationId']

    \# Retain schema details

    for schema in openapi_dict['components']['schemas'].values():
        if 'description' in schema:
            schema['x-original-description'] = schema['description']

    \# Update to OpenAPI version 3.1.0

    openapi_dict['openapi'] = "3.1.0"

    \# Security schemes

    security_schemes = {}

    if 'securityDefinitions' in openapi_dict:
        logging.warning(
            f"'securityDefinitions' found - converting to 'securitySchemes'. "
            "This key is deprecated in OpenAPI 3.1.0 and should be replaced with 'securitySchemes'."
        )
        security_definitions = openapi_dict.pop('securityDefinitions')
        for def_name, definition in security_definitions.items():
            scheme = {
                'type': definition.get('type', 'http'),
                'scheme': definition.get('scheme', 'bearer')
            }
            if 'bearerFormat' in definition:
                scheme['bearerFormat'] = definition['bearerFormat']
            if 'description' in definition:
                scheme['description'] = definition['description']
            security_schemes[def_name] = scheme

    openapi_dict['components']['securitySchemes'] = security_schemes

    \# YAML conversion

    yaml_string = yaml.dump(openapi_dict, sort_keys=True)

    return yaml_string

\# Input validation functions

def validate_required_fields(openapi_dict):
    required_fields = ['openapi', 'info', 'paths']
    for field in required_fields:
        if field not in openapi_dict:
            raise Exception(f"Field '{field}' is required")

def validate_openapi_version(openapi_dict, versions=["3.0.0", "3.1.0"]):
    if openapi_dict['openapi'] not in versions:
        raise Exception(
            f"Input version must be one of {versions}. Found {openapi_dict['openapi']}"
        )

def check_incompatible_inputs(openapi_dict, incompatible_keys=['securityDefinitions']):
    for key in incompatible_keys:
        if key in openapi_dict:
            raise Exception(f"Input contains deprecated key '{key}'.")

```


### md_content_aggregator.py
```python
'''
Name: md_content_aggregator.py

Purpose:
The MD Content Aggregator is designed to scan a directory structure, extracting content from files that match specific criteria, and generate a content.md file for each directory and an all-contents.md file in the root directory. The generated files contain aggregated content from the scanned files, appropriately formatted in Markdown.

Methods and Functionalities:
- escape_markdown_characters_in_python_code(code: str) -> str:
    Escapes markdown special characters in a given string containing Python code to ensure they're not interpreted as markdown formatting.

- get_repo_structure(directory: str) -> str:
    Uses the tree command to generate a JSON representation of the directory structure.

- should_include(file_path: str, is_dir: bool = False) -> bool:
    Determines if a file or directory should be included based on specified patterns and extensions.

- directory_structure(directory: str) -> str:
    Retrieve the structure of a specific directory in JSON format.

- generate_filename(directory: str) -> str:
    Generates the filename for the content.md file based on the directory structure.

- generate_md_files(directory: str) -> None:
    Asynchronously processes a directory to identify files for aggregation and generate a content.md file.

- combine_md_files() -> None:
    Generates the all-contents.md file in the root directory by combining all the content.md files.

- process_directory(directory: str) -> None:
    Recursively processes directories to generate content.md files.

- main() -> None:
    The main asynchronous function that initiates the content aggregation process.

Configuration and Constants:
- EXCLUDED_EXTENSIONS: File extensions that are to be ignored.
- EXCLUSIVE_EXTENSION: Patterns and directories that the content aggregation process should exclusively focus on.
- Logging: Captures information, warnings, and error messages to script.log.

How to Use:
1. Ensure the script has access to the directories you wish to scan.
2. Run the script.
3. Once complete, find a content.md file in each directory and an all-contents.md file in the root directory.

Note: The script uses asynchronous file operations for improved performance with a large number of files or large-sized files. Ensure required libraries are installed.
'''

import os
import asyncio
import aiofiles
import logging
import fnmatch
import subprocess
import re


logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler("script.log"), logging.StreamHandler()])

EXCLUDED_EXTENSIONS = ['.db', '.log', '.sh', '.pyc', 'content.md']
EXCLUSIVE_EXTENSION = ['*.py', '*.md', 'docs/*', 'git-utils/*', 'src/*', '.']

added_content = set()


def escape_markdown_characters_in_python_code(code: str) -> str:
    """Escape markdown special characters within Python code."""
    lines = code.split('\n')
    escaped_lines = []
    for line in lines:
        if line.strip().startswith("#"):
            line = line.replace("#", r"\#")
            line = line.replace("*", r"\*")
            line = line.replace("_", r"\_")
            line = line.replace("[", r"\[")
            line = line.replace("]", r"\]")
            line = line.replace("(", r"\(")
            line = line.replace(")", r"\)")
            line = line.replace(">", r"\>")
            line = line.replace("-", r"\-")
        escaped_lines.append(line)
    return '\n'.join(escaped_lines)

def get_repo_structure(directory):
    """Retrieve the repository structure in JSON format."""
    try:
        result = subprocess.run(['tree', '--dirsfirst', '-J', directory],
                                capture_output=True, text=True, check=True)
        return result.stdout
    except subprocess.CalledProcessError as e:
        logging.error(f"Error getting repo structure: {e}")
        return ""

def should_include(file_path, is_dir=False):
    """
    Determine if a file or directory should be included based on exclusive and excluded patterns.
    """
    if is_dir:
        \# Explicitly check for directories using string methods
        dir_checks = ['docs', 'git-utils', 'src']
        return any(check in file_path for check in dir_checks)

    if any(fnmatch.fnmatch(file_path, pattern) for pattern in EXCLUDED_EXTENSIONS):
        return False

    return any(fnmatch.fnmatch(file_path, pattern) for pattern in EXCLUSIVE_EXTENSION)



def directory_structure(directory):
    """Retrieve the structure of a specific directory in JSON format."""
    try:
        result = subprocess.run(['tree', '--dirsfirst', '-J', directory],
                                capture_output=True, text=True, check=True)
        return result.stdout
    except subprocess.CalledProcessError as e:
        logging.error(f"Error getting directory structure: {e}")
        return ""



def generate_filename(directory):
    """Generate filename based on the directory structure."""
    if directory == ".":
        return "root-content.md"
    else:
        parts = [part for part in directory.split(os.sep) if part != "."]
        return "-".join(parts) + "-content.md"

async def generate_md_files(directory):
    """Generate content.md files for the specified directory."""
    logging.info(f"Processing directory: {directory}")
    content_filepath = os.path.join(directory, generate_filename(directory))
    \# Delete the existing content.md file if it exists
    if os.path.exists(content_filepath):
        os.remove(content_filepath)
    toc_content = "## Table of Contents\n"
    dir_structure = f"\n\n## Directory Structure\n```json\n{directory_structure(directory)}\n```\n\n"
    file_content_list = []

    for entry in os.scandir(directory):
        if entry.is_file() and should_include(entry.path) and entry.name != content_filepath:
            try:
                async with aiofiles.open(entry.path, 'r', encoding='utf-8') as f:
                    file_content = await f.read()

                if file_content in added_content:
                    continue
                added_content.add(file_content)

                toc_content += f"- [{entry.name}](#{entry.name.replace('.', '-')})\n"

                if entry.name.endswith('.py'):
                    file_content = escape_markdown_characters_in_python_code(file_content)
                    file_content_list.append(f"\n### {entry.name}\n```python\n{file_content}\n```\n")
                elif entry.name.endswith('.md'):
                    file_content_list.append(f"\n### {entry.name}\n{file_content}\n")
            except UnicodeDecodeError:
                logging.warning(f"Unable to read file {entry.name} as it's not in UTF-8 encoding. Skipping.")

    async with aiofiles.open(content_filepath, 'w') as f:
        await f.write(toc_content + dir_structure + '\n'.join(file_content_list))


def combine_md_files():
    combined_content_sections = ["# Project Documentation\n\n", "## Table of Contents\n"]
    \# Delete the existing all\-contents.md file if it exists
    if os.path.exists("all-contents.md"):
        os.remove("all-contents.md")
    toc_links = set()

    for directory, _, filenames in os.walk("."):
        content_md_name = generate_filename(directory)
        content_md_path = os.path.join(directory, content_md_name)
        if content_md_name in filenames:
            logging.info(f"Reading {content_md_path}")
            with open(content_md_path, 'r', encoding='utf-8') as f:
                content = f.read()

            sections = content.split("\n## ")
            toc_section = sections[0]
            toc_links.update(re.findall(r"- \[.*?\]\(.*?\)", toc_section))
            for section in sections[1:]:
                combined_content_sections.append("## " + section)

    combined_content_sections.insert(2, "\n".join(toc_links))
    combined_content_sections.append("\n\n## Repo Structure\n```json\n")
    combined_content_sections.append(get_repo_structure("."))
    combined_content_sections.append("\n```\n\n")

    with open("all-contents.md", 'w', encoding='utf-8') as f:
        f.write('\n'.join(combined_content_sections))



async def process_directory(directory):
    """Process a directory and its subdirectories to generate content.md files."""
    logging.info(f"Checking directory: {directory}")
    await generate_md_files(directory)

    for entry in os.scandir(directory):
        if entry.is_dir() and should_include(entry.path, is_dir=True):
            await process_directory(entry.path)

async def main():
    """Main asynchronous function to start content aggregation."""
    global added_content
    added_content = set()  # Reset the set
    await process_directory(".")
    combine_md_files()

if __name__ == "__main__":
    asyncio.run(main())
```

## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [.-src-__pycache__-content.md](#--src-__pycache__-content-md)
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### .-src-__pycache__-content.md
## Table of Contents
- [content.md](#content-md)


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```





### content.md
## Table of Contents


## Directory Structure
```json
[
  {"type":"directory","name":"./src/__pycache__","contents":[
    {"type":"file","name":"content.md"},
    {"type":"file","name":"openapi_converter.cpython-311.pyc"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```



## Directory Structure
```json
[
  {"type":"directory","name":"./docs","contents":[
    {"type":"file","name":"CODE_OF_CONDUCT.md"},
    {"type":"file","name":"SECURITY.md"}
  ]}
,
  {"type":"report","directories":1,"files":2}
]

```


### CODE_OF_CONDUCT.md
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
inayet@dreamsapi.com.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.


### SECURITY.md
### SECURITY.md

```markdown
# Security Policy

![Security](https://www.vectorlogo.zone/logos/snykio/snykio-ar21.svg)

## Supported Versions

Currently, we support the following versions of "Convert OpenAPI 3.0.0 specs to OpenAPI 3.1.0" with security updates:

| Version | Supported          |
| ------- | ------------------ |
| 1.2.x   | :white_check_mark: |
| 1.1.x   | :white_check_mark: |
| 1.0.x   | :x:                |

## Reporting a Vulnerability

If you discover any vulnerabilities or security issues, kindly follow these steps:

1. **Avoid Creating Public Issues**: Please do not discuss vulnerabilities in public to prevent malicious use.
2. **Contact Us Directly**: Send a detailed vulnerability report to [inayet@dreamsapi.com](mailto:inayet@dreamsapi.com).
3. **Response Time**: We prioritize our users' security and will address the report as soon as possible, typically within 48 hours. You'll receive an update on the reported vulnerability, and we'll work together to address the concern.

```



## Repo Structure
```json

[
  {"type":"directory","name":".","contents":[
    {"type":"directory","name":"assets","contents":[
      {"type":"file","name":"openapi310.png"}
    ]},
    {"type":"directory","name":"configuration","contents":[
      {"type":"file","name":"display_project_files.ignore.bk"},
      {"type":"file","name":"display_project_files.include.bk"}
    ]},
    {"type":"directory","name":"data","contents":[
      {"type":"file","name":"calendars.json"},
      {"type":"file","name":"calendars.yml"}
    ]},
    {"type":"directory","name":"docs","contents":[
      {"type":"file","name":"CODE_OF_CONDUCT.md"},
      {"type":"file","name":"docs-content.md"},
      {"type":"file","name":"SECURITY.md"}
    ]},
    {"type":"directory","name":"git-utils","contents":[
      {"type":"file","name":"git-utils-content.md"},
      {"type":"file","name":"useful.git-create-new-repo.py"},
      {"type":"file","name":"useful.git-update-all-branches.py"}
    ]},
    {"type":"directory","name":"src","contents":[
      {"type":"directory","name":"__pycache__","contents":[
        {"type":"file","name":"content.md"},
        {"type":"file","name":"openapi_converter.cpython-311.pyc"},
        {"type":"file","name":"src-__pycache__-content.md"}
      ]},
      {"type":"file","name":"__init__.py"},
      {"type":"file","name":"md_content_aggregator.py"},
      {"type":"file","name":"openapi_converter_main.py"},
      {"type":"file","name":"openapi_converter.py"},
      {"type":"file","name":"src-content.md"}
    ]},
    {"type":"directory","name":"utilities","contents":[
      {"type":"file","name":"organize.py"}
    ]},
    {"type":"file","name":"License"},
    {"type":"file","name":"README.md"},
    {"type":"file","name":"repodir.txt"},
    {"type":"file","name":"requirements.txt"},
    {"type":"file","name":"root-content.md"},
    {"type":"file","name":"script.log"}
  ]}
,
  {"type":"report","directories":9,"files":26}
]


```

